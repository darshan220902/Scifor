{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Natural Language Processing (NLP) is a branch of artificial intelligence (AI) that focuses on the interaction between computers and human languages. The goal of NLP is to enable computers to understand, interpret, and generate human-like language , Use for Tokenization,Part-of-Speech Tagging(pos),Speech Recognition"
      ],
      "metadata": {
        "id": "r6nfhMB6GYiw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###NLTK is a powerful Python library for working with human language data. It provides easy-to-use interfaces for performing numerous NLP tasks and is widely used in research and education.Use for Tokenization,Part-of-Speech Tagging(pos)\n"
      ],
      "metadata": {
        "id": "eTq95ugVGoqs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "\n",
        "\n",
        "text = \"What is NLP ? NLP is Natural Language Processing\"\n",
        "\n",
        "words = word_tokenize(text)\n",
        "sentences = sent_tokenize(text)\n",
        "\n",
        "print(\"Tokenized Words:\", words)\n",
        "print(\"Tokenized Sentences:\", sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9wtYw1iGa4w",
        "outputId": "b46a08e5-a24e-4fa1-d922-c7152bef4fb2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized Words: ['What', 'is', 'NLP', '?', 'NLP', 'is', 'Natural', 'Language', 'Processing']\n",
            "Tokenized Sentences: ['What is NLP ?', 'NLP is Natural Language Processing']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "jSmt9Q3UFjLq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### spaCy is an open-source natural language processing (NLP) library designed to perform various tasks related to natural language understanding and processing. It is written in Python and is known for its efficiency, speed, and ease of use. spaCy provides pre-trained models for several languages, allowing developers to implement NLP tasks without having to build models from scratch.Use for pos,tokenization,ner(named entity recognization)\n"
      ],
      "metadata": {
        "id": "rblRNAztIEah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install spaCy\n",
        "#!pip install -U spacy\n",
        "\n",
        "# Download spaCy English model\n",
        "#!python -m spacy download en\n",
        "\n",
        "import spacy\n",
        "\n",
        "# Example text\n",
        "text = \"Tom and harry are friends and they live in USA.\"\n",
        "\n",
        "# NER with spaCy\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "doc = nlp(text)\n",
        "\n",
        "# Display named entities\n",
        "entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
        "print(\"Named Entities:\", entities)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEaCj3KuIFqt",
        "outputId": "c5d729b0-49ec-4dd8-8628-11818816b56f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Named Entities: [('Tom', 'PERSON'), ('harry', 'PERSON'), ('USA', 'GPE')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0zg0w-UNIGtZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}